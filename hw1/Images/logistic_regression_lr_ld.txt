Namespace(compute_vocab=False, cross_k=10, embed_algo='glove', epochs=100, hidden_state='256,256,128,64,32', hidden_tuning=None, lam=0.1, lr='1.0,0.5,0.1,0.05,0.01', network='lr', p=0.1, regulariser='l2')
[1.0, 0.5, 0.1, 0.05, 0.01]



Running Logistic Regression: lambda 1.0
43.90243902439025 66.30532971996386
39.430894308943095 65.40198735320686
37.398373983739845 65.04065040650407
36.178861788617894 65.06323396567299
34.95934959349594 64.91418247515809
34.55284552845529 64.99548328816621
35.075493612078986 65.1180797522261
34.95934959349594 65.0293586269196
35.772357723577244 64.84994479574425
36.58536585365854 64.8780487804878
Train Accuracy: 64.8780487804878 
Validation Accuracy: 36.58536585365854
0.2315562869799961
[0.12244898 0.         0.18823529 0.46153846 0.36090226 0.
 0.2972973  0.47058824 0.13793103 0.         0.25263158 0.31097561
 0.37096774 0.         0.         0.47159091 0.49134948]



Running Logistic Regression: lambda 0.5
40.65040650406504 85.90785907859079
39.43089430894309 85.32068654019874
38.75338753387533 85.3658536585366
36.38211382113821 85.65943992773262
34.796747967479675 85.83559168925024
34.41734417344174 85.81752484191509
34.37862950058072 85.88204929668345
34.2479674796748 85.86269196025293
33.694670280036135 85.87774766636555
33.73983739837398 85.80849141824751
Train Accuracy: 85.80849141824751 
Validation Accuracy: 33.73983739837398
0.22404564980931993
[0.08333333 0.         0.17073171 0.42553191 0.32061069 0.
 0.34615385 0.34722222 0.15625    0.06896552 0.36363636 0.2835443
 0.26946108 0.         0.         0.43037975 0.54295533]



Running Logistic Regression: lambda 0.1
37.39837398373984 99.6386630532972
40.24390243902439 99.6386630532972
38.21138211382114 99.6386630532972
38.21138211382114 99.68383017163504
38.21138211382114 99.67479674796746
39.02439024390244 99.69888587774766
38.79210220673635 99.71609239901922
37.90650406504065 99.70641373080397
37.579042457091234 99.69888587774767
37.96747967479674 99.69286359530263
Train Accuracy: 99.69286359530263 
Validation Accuracy: 37.96747967479674
0.2630723153632512
[0.26415094 0.         0.15189873 0.43617021 0.34965035 0.
 0.36       0.46590909 0.17910448 0.07692308 0.37681159 0.35643564
 0.27355623 0.11111111 0.         0.52121212 0.54929577]



Running Logistic Regression: lambda 0.05
39.83739837398374 99.6386630532972
36.17886178861789 99.6386630532972
37.12737127371273 99.6386630532972
37.39837398373984 99.6386630532972
37.07317073170732 99.67479674796748
37.94037940379404 99.66877446552242
38.21138211382114 99.66447283520453
36.78861788617886 99.66124661246613
36.043360433604335 99.69888587774767
36.422764227642276 99.69286359530263
Train Accuracy: 99.69286359530263 
Validation Accuracy: 36.422764227642276
0.23788394388652018
[0.15686275 0.         0.12345679 0.41340782 0.30344828 0.
 0.37735849 0.47252747 0.20512821 0.         0.32653061 0.35764706
 0.28       0.         0.         0.5        0.52765957]



Running Logistic Regression: lambda 0.01
24.390243902439025 99.8193315266486
26.422764227642276 99.8193315266486
27.100271002710027 99.81933152664858
25.8130081300813 99.8193315266486
26.178861788617883 99.8193315266486
26.016260162601622 99.81933152664861
25.783972125435533 99.81933152664861
25.71138211382113 99.81933152664861
25.293586269196016 99.81933152664861
25.121951219512187 99.83739837398375
Train Accuracy: 99.83739837398375 
Validation Accuracy: 25.121951219512187
0.18025418506583002
[0.14705882 0.         0.10869565 0.25       0.15602837 0.
 0.25514403 0.4        0.12048193 0.04       0.31067961 0.27821522
 0.21556886 0.         0.05555556 0.33540373 0.39148936]
